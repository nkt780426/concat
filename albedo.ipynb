{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vohoang/miniconda3/envs/torch/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.22). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "2024-12-20 13:02:33.313901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-20 13:02:34.683601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import albumentations as A\n",
    "\n",
    "from going_modular.dataloader.magface import create_magface_dataloader\n",
    "from going_modular.model.MagFaceRecognition import MagFaceRecognition\n",
    "from going_modular.train_eval.magface.train import fit\n",
    "from going_modular.loss.MagLoss import MagLoss\n",
    "from going_modular.utils.MultiMetricEarlyStopping import MultiMetricEarlyStopping\n",
    "from going_modular.utils.ModelCheckPoint import ModelCheckpoint\n",
    "from going_modular.utils.transforms import RandomResizedCropRect, GaussianNoise\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "CONFIGURATION = {\n",
    "    # Thư mục\n",
    "    'type': 'albedo',\n",
    "    'train_dir': './Dataset/Albedo/train',\n",
    "    'test_dir': './Dataset/Albedo/test',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'backbone': 'inception-resnet-v1',\n",
    "    'epochs': 500,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 224,\n",
    "    'num_class': len(os.listdir('./Dataset/Albedo/train')),\n",
    "    'embedding_size': 512,\n",
    "    \n",
    "    'learning_rate': 0.2,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'alpha': 0.9,\n",
    "    \n",
    "    # Hàm m(ai) giúp thay đổi ai từ 0.25 đến 1.6\n",
    "    'scale': 64,\n",
    "    'lambda_g': 20,\n",
    "    'l_margin': 0.45, \n",
    "    'u_margin': 0.8,\n",
    "    'l_a': 10, \n",
    "    'u_a': 110,\n",
    "}\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    RandomResizedCropRect(256),\n",
    "    GaussianNoise(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=CONFIGURATION['image_size'], width=CONFIGURATION['image_size'])\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader = create_magface_dataloader(CONFIGURATION, train_transform, test_transform)\n",
    "\n",
    "model = MagFaceRecognition(CONFIGURATION).to(device)\n",
    "criterion = MagLoss(conf = CONFIGURATION)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIGURATION['learning_rate'])\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=40, T_mult=1, eta_min=1e-6)\n",
    "checkpoint_path = os.path.abspath('checkpoint/magface/' + CONFIGURATION['type'] + '/models/checkpoint.pth')\n",
    "modle_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)\n",
    "earlystop_dir = os.path.abspath('checkpoint/magface/' + CONFIGURATION['type'] + '/models')\n",
    "early_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['test_cosine_auc', 'test_cosine_accuracy', 'test_euclidean_auc', 'test_euclidean_accuracy'],\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=40\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\ttrain: loss 3.758 | loss id   3.73 | top_1_acc 0.0045 | top_5_acc 0.0180 | cos_auc: 0.5637 | cos_acc: 0.3837 | eu_auc: 0.5561 | eu_acc: 0.4960\n",
      "\ttest: cos_auc: 0.6246 | cos_acc: 0.6246 | eu_auc: 0.5989 | eu_acc: 0.7513\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/checkpoint/magface/albedo/models/checkpoint.pth\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodle_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/going_modular/train_eval/magface/train.py:50\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(conf, start_epoch, model, device, train_dataloader, val_dataloader, criterion, optimizer, scheduler, early_stopping, model_checkpoint)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss_id, loss_g \u001b[38;5;241m=\u001b[39m criterion(logits, target, x_norm)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_id \u001b[38;5;241m+\u001b[39m loss_g\n\u001b[0;32m---> 50\u001b[0m acc1, acc5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_id_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# update metric\u001b[39;00m\n\u001b[1;32m     53\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/going_modular/train_eval/magface/train_id_acc.py:13\u001b[0m, in \u001b[0;36mtrain_id_accuracy\u001b[0;34m(predict, target)\u001b[0m\n\u001b[1;32m     10\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m     11\u001b[0m correct \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(pred))\n\u001b[0;32m---> 13\u001b[0m correct_1 \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m correct_5 \u001b[38;5;241m=\u001b[39m correct[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correct_1, correct_5\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(CONFIGURATION, 0, model, device, train_dataloader, test_dataloader, criterion, optimizer, scheduler, early_stopping, modle_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoint/magface/' + CONFIGURATION['type'] + '/models/checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(CONFIGURATION, 246, model, device, train_dataloader, test_dataloader, criterion, optimizer, scheduler, early_stopping, modle_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
