{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from going_modular.dataloader.magface import create_magface_dataloader\n",
    "from going_modular.model.MagFaceRecognition import MagFaceRecognition\n",
    "from going_modular.train_eval.train import fit\n",
    "from going_modular.loss.MagLoss import MagLoss\n",
    "from going_modular.utils.MultiMetricEarlyStopping import MultiMetricEarlyStopping\n",
    "from going_modular.utils.ModelCheckPoint import ModelCheckpoint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    # Thư mục\n",
    "    'type': 'albedo',\n",
    "    'train_dir': './Dataset/Albedo/train',\n",
    "    'test_dir': './Dataset/Albedo/test',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'backbone': 'iresnet101',\n",
    "    'epochs': 2000,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 224,\n",
    "    'num_class': len(os.listdir('./Dataset/Albedo/train')),\n",
    "    'embedding_size': 512,\n",
    "    \n",
    "    'learning_rate': 0.1,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'alpha': 0.9,\n",
    "    \n",
    "    # Hàm m(ai) giúp thay đổi ai từ 0.25 đến 1.6\n",
    "    'scale': 64,\n",
    "    'lambda_g': 20,\n",
    "    'l_margin': 0.45, \n",
    "    'u_margin': 0.8,\n",
    "    'l_a': 10, \n",
    "    'u_a': 110,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x711a6bff92b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = create_magface_dataloader(CONFIGURATION, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: torch.Size([16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "print(f\"Labels: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(\n",
    "#     model=MagFaceRecognition(CONFIGURATION), \n",
    "#     verbose=0, \n",
    "#     col_width=20, \n",
    "#     row_settings=[\"var_names\"],\n",
    "#     col_names=[\"input_size\", 'output_size', \"num_params\", \"trainable\"],\n",
    "#     input_size=(1,3,224,224)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MagFaceRecognition(CONFIGURATION).to(device)\n",
    "criterion = MagLoss(conf = CONFIGURATION)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIGURATION['learning_rate'])\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=40, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "checkpoint_path = os.path.abspath('checkpoint/magface/albedo/' + CONFIGURATION['backbone'] + '/models/checkpoint.pth')\n",
    "modle_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)\n",
    "earlystop_dir = os.path.abspath('checkpoint/magface/albedo/' + CONFIGURATION['backbone'] + '/models')\n",
    "early_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['val_euclidean_accuracy', 'val_cosine_accuracy', 'val_auc_euclidean', 'val_auc_cosine'],\n",
    "    patience=40,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=60\n",
    ")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\ttrain: loss 3.669 | loss id   3.64 | top_1_acc 0.0045 | top_5_acc 0.0277 | acc_eu: 0.496 | acc_cos: 0.576 | auc_eu: 0.572 | auc_cos: 0.585\n",
      "\tval: acc_eu: 0.533 | acc_cos: 0.803 | auc_eu: 0.609 | auc_cos: 0.653\n",
      "\u001b[36m\tSaving model to /media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/checkpoint/magface/albedo/iresnet101/models/checkpoint.pth\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodle_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/going_modular/train_eval/train.py:56\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(conf, start_epoch, model, device, train_dataloader, val_dataloader, criterion, optimizer, scheduler, early_stopping, model_checkpoint)\u001b[0m\n\u001b[1;32m     54\u001b[0m loss_id, loss_g \u001b[38;5;241m=\u001b[39m criterion(logits, target, x_norm)\n\u001b[1;32m     55\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_id \u001b[38;5;241m+\u001b[39m loss_g\n\u001b[0;32m---> 56\u001b[0m acc1, acc5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_id_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# update metric\u001b[39;00m\n\u001b[1;32m     59\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/going_modular/train_eval/train_id_acc.py:9\u001b[0m, in \u001b[0;36mtrain_id_accuracy\u001b[0;34m(predict, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m      7\u001b[0m correct \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(pred))\n\u001b[0;32m----> 9\u001b[0m correct_1 \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m correct_5 \u001b[38;5;241m=\u001b[39m correct[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correct_1, correct_5\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(CONFIGURATION, 0, model, device, train_dataloader, val_dataloader, criterion, optimizer, scheduler, early_stopping, modle_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 29938), started 0:00:04 ago. (Use '!kill 29938' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dd90586f0bd2996b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dd90586f0bd2996b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir checkpoint/magface/albedo/iresnet101/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB: 1.45068965517p/epoch\n"
     ]
    }
   ],
   "source": [
    "print('TB: 1.45068965517p/epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
