{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.dataloader.magface import create_magface_dataloader\n",
    "from going_modular.model.MagFaceRecognition import MagFaceRecognition\n",
    "from going_modular.loss.MagLoss import MagLoss\n",
    "from going_modular.utils.metrics import AverageMeter, ProgressMeter\n",
    "from going_modular.train_eval.train_id_acc import train_id_accuracy\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    # Thư mục\n",
    "    'type': 'normalmap',\n",
    "    'train_dir': './Dataset/Normal_Map/train',\n",
    "    'test_dir': './Dataset/Normal_Map/test',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'epochs': 2000,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 224,\n",
    "    'num_class': len(os.listdir('./Dataset/Normal_Map/train')),\n",
    "    'embedding_size': 512,\n",
    "    \n",
    "    'learning_rate': 0.1,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'alpha': 0.9,\n",
    "    \n",
    "    # Hàm m(ai) giúp thay đổi ai từ 0.25 đến 1.6\n",
    "    'scale': 64,\n",
    "    'lambda_g': 20,\n",
    "    'l_margin': 0.45, \n",
    "    'u_margin': 0.8,\n",
    "    'l_a': 10, \n",
    "    'u_a': 110,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(224),\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.CenterCrop(224),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = create_magface_dataloader(CONFIGURATION, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: tensor([ 84,  66, 131,  69,  96, 114,  56, 145, 149, 129, 110, 190,  25,  81,\n",
      "        195,   8])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "print(f\"Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MagFaceRecognition(CONFIGURATION).to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        CONFIGURATION['learning_rate'],\n",
    "        momentum=CONFIGURATION['momentum'],\n",
    "        weight_decay=CONFIGURATION['weight_decay']\n",
    ")\n",
    "# optimizer = torch.optim.SGD(\n",
    "#         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#         args.lr,\n",
    "#         momentum=args.momentum,\n",
    "#         weight_decay=args.weight_decay)\n",
    "#     pprint.pprint(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIGURATION['learning_rate'])\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "criterion = MagLoss(CONFIGURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ROC(dataloader, model, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_list = []\n",
    "\n",
    "        for batch in dataloader:\n",
    "            images, ids = batch\n",
    "            images = images.to(device)\n",
    "            outputs = model.get_embedding(images)\n",
    "            \n",
    "            for i in range(outputs.size(0)):\n",
    "                outputs_list.append((ids[i].item(), outputs[i].cpu().numpy()))\n",
    "                \n",
    "        scores_dis = []\n",
    "        labels_dis = []\n",
    "        scores_cos = []\n",
    "        labels_cos = []\n",
    "\n",
    "        for i in range(len(outputs_list)):\n",
    "            for j in range(i + 1, len(outputs_list)):\n",
    "                id1, tensor1 = outputs_list[i]\n",
    "                id2, tensor2 = outputs_list[j]\n",
    "\n",
    "                # Chuyển đổi numpy array về tensor và chuyển lên thiết bị cuda\n",
    "                tensor1 = torch.tensor(tensor1)\n",
    "                tensor2 = torch.tensor(tensor2)\n",
    "\n",
    "                # Tính khoảng cách Euclidean\n",
    "                score_dis = F.pairwise_distance(tensor1, tensor2).item()\n",
    "                # Tính cosine similarity\n",
    "                score_cos = F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n",
    "\n",
    "                # Lưu độ tương đồng và nhãn\n",
    "                scores_dis.append(score_dis)\n",
    "                labels_dis.append(0 if id1 == id2 else 1)\n",
    "                scores_cos.append(score_cos)\n",
    "                labels_cos.append(1 if id1 == id2 else 0)\n",
    "\n",
    "        y_true_dis = np.array(labels_dis)\n",
    "        y_scores_dis = np.array(scores_dis)\n",
    "        fpr_dis, tpr_dis, thresholds_dis = roc_curve(y_true_dis, y_scores_dis)\n",
    "        roc_auc_dis = auc(fpr_dis, tpr_dis)\n",
    "\n",
    "        y_true_cos = np.array(labels_cos)\n",
    "        y_scores_cos = np.array(scores_cos)\n",
    "        fpr_cos, tpr_cos, thresholds_cos = roc_curve(y_true_cos, y_scores_cos)\n",
    "        roc_auc_cos = auc(fpr_cos, tpr_cos)\n",
    "    return roc_auc_dis, roc_auc_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\ttrain: Train Loss 3.736 | Train Loss Id   3.71 | Train Top 1 Accuracy   0.00 | Train Top 5 Accuracy   0.02 | roc_dis: 0.550 | auc_cos: 0.562\n",
      "\tval: roc_dis: 0.526 | auc_cos: 0.574\n",
      "Epoch 2:\n",
      "\ttrain: Train Loss 1.946 | Train Loss Id   1.92 | Train Top 1 Accuracy   0.01 | Train Top 5 Accuracy   0.03 | roc_dis: 0.553 | auc_cos: 0.532\n",
      "\tval: roc_dis: 0.550 | auc_cos: 0.542\n",
      "Epoch 3:\n",
      "\ttrain: Train Loss 0.626 | Train Loss Id   0.60 | Train Top 1 Accuracy   0.00 | Train Top 5 Accuracy   0.02 | roc_dis: 0.553 | auc_cos: 0.522\n",
      "\tval: roc_dis: 0.552 | auc_cos: 0.536\n",
      "Epoch 4:\n",
      "\ttrain: Train Loss 0.562 | Train Loss Id   0.54 | Train Top 1 Accuracy   0.01 | Train Top 5 Accuracy   0.03 | roc_dis: 0.553 | auc_cos: 0.546\n",
      "\tval: roc_dis: 0.540 | auc_cos: 0.551\n",
      "Epoch 5:\n",
      "\ttrain: Train Loss 0.497 | Train Loss Id   0.47 | Train Top 1 Accuracy   0.01 | Train Top 5 Accuracy   0.04 | roc_dis: 0.566 | auc_cos: 0.580\n",
      "\tval: roc_dis: 0.581 | auc_cos: 0.630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m loss_id, loss_g \u001b[38;5;241m=\u001b[39m criterion(logits, target, x_norm)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_id \u001b[38;5;241m+\u001b[39m loss_g\n\u001b[0;32m---> 17\u001b[0m acc1, acc5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_id_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# update metric\u001b[39;00m\n\u001b[1;32m     20\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/Bachelor-s-Project/going_modular/train_eval/train_id_acc.py:9\u001b[0m, in \u001b[0;36mtrain_id_accuracy\u001b[0;34m(predict, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m      7\u001b[0m correct \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(pred))\n\u001b[0;32m----> 9\u001b[0m correct_1 \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m correct_5 \u001b[38;5;241m=\u001b[39m correct[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correct_1, correct_5\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(CONFIGURATION['epochs']):\n",
    "    train_loss = AverageMeter('Train Loss', ':.3f')\n",
    "    train_loss_id = AverageMeter('Train Loss Id', ':6.2f')\n",
    "    train_id_top1 = AverageMeter('Train Top 1 Accuracy', ':6.2f')\n",
    "    train_id_top5 = AverageMeter('Train Top 5 Accuracy', ':6.2f')\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for index, (input, target) in enumerate(train_dataloader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        logits, x_norm = model(input)\n",
    "        \n",
    "        # caculate metric\n",
    "        loss_id, loss_g = criterion(logits, target, x_norm)\n",
    "        loss = loss_id + loss_g\n",
    "        acc1, acc5 = train_id_accuracy(logits[0], target)\n",
    "        \n",
    "        # update metric\n",
    "        batch_size = input.size(0)\n",
    "        train_loss.update(loss.item(), batch_size)\n",
    "        train_loss_id.update(loss_id.item(), batch_size)\n",
    "        train_id_top1.update(acc1, batch_size)\n",
    "        train_id_top5.update(acc5, batch_size)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    train_loss.compute()\n",
    "    train_loss_id.compute()\n",
    "    train_id_top1.compute()\n",
    "    train_id_top5.compute()\n",
    "    \n",
    "    train_roc_dis, train_auc_cos = check_ROC(train_dataloader, model, device)\n",
    "    \n",
    "    val_roc_dis, val_auc_cos = check_ROC(val_dataloader, model, device)\n",
    "    \n",
    "    train_metrics = [\n",
    "        train_loss, \n",
    "        train_loss_id, \n",
    "        train_id_top1 * 100,\n",
    "        train_id_top5 * 100,\n",
    "        f\"roc_dis: {train_roc_dis:.3f}\",\n",
    "        f\"auc_cos: {train_auc_cos:.3f}\",\n",
    "    ]\n",
    "    \n",
    "    val_metrics = [\n",
    "        f\"roc_dis: {val_roc_dis:.3f}\",\n",
    "        f\"auc_cos: {val_auc_cos:.3f}\",\n",
    "    ]\n",
    "    \n",
    "    process = ProgressMeter(\n",
    "        train_meters=train_metrics,\n",
    "        val_meters=val_metrics,\n",
    "        prefix=f\"Epoch {epoch + 1}:\"\n",
    "    )\n",
    "    \n",
    "    process.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2, os\n",
    "\n",
    "# os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = './Dataset/Normal_Map/train'\n",
    "\n",
    "# for id in os.listdir(dataset):\n",
    "#     id_path = os.path.join(dataset, id)\n",
    "#     for filename in os.listdir(id_path):\n",
    "#         image_path = os.path.join(id_path, filename)\n",
    "#         image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "#         height, width = image.shape[:2]\n",
    "#         if width != 224 or height != 224:\n",
    "#             print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 244, 3)\n"
     ]
    }
   ],
   "source": [
    "# image = cv2.imread('./Dataset/Normal_Map/train/2011/2008-03-27_17-47-12.exr', cv2.IMREAD_UNCHANGED)\n",
    "# print(image.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
