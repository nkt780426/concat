{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 20:15:54.554638: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-21 20:15:55.288957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "from going_modular.model.TripletFaceRecognition import EmbeddingNet_Concat_V2, TripletNet_Concat_V2\n",
    "from going_modular.dataloader.triplet import TripletDatasetConcatV2\n",
    "from going_modular.loss.TripletLoss import TripletLoss\n",
    "from going_modular.dataloader.triplet import CustomExrDatasetConCatV2\n",
    "from going_modular.utils.MultiMetricEarlyStopping import MultiMetricEarlyStopping\n",
    "from going_modular.utils.ModelCheckPoint import ModelCheckpoint\n",
    "from going_modular.utils.transforms import RandomResizedCropRect, GaussianNoise\n",
    "from going_modular.train_eval.triplet.train import fit\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "CONFIGURATION = {\n",
    "    'type': 'concat',\n",
    "    # Thư mục\n",
    "    'data_dir': './Dataset',\n",
    "    'checkpoint_dir': './checkpoint/test/',\n",
    "    'normalmap_checkpoint': './checkpoint/new/normalmap/iresnet18/models/best_cosine_auc_286.pth',\n",
    "    'albedo_checkpoint': './checkpoint/new/albedo/iresnet18/models/best_cosine_auc_240.pth',\n",
    "    'depthmap_checkpoint': './checkpoint/new/depthmap/iresnet34/models/best_cosine_auc_271.pth',\n",
    "\n",
    "    # Cấu hình train\n",
    "    'epochs': 119,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 4,\n",
    "    'image_size': 256,\n",
    "    'embedding_size': 512,\n",
    "    \n",
    "    'start_lr': 1e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'alpha': 0.9,\n",
    "    \n",
    "    # triplet\n",
    "    'margin': 1.,\n",
    "}\n",
    "\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    RandomResizedCropRect(256),\n",
    "    GaussianNoise(),\n",
    "], additional_targets={\n",
    "    'albedo': 'image',\n",
    "    'depthmap': 'image'\n",
    "})\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=CONFIGURATION['image_size'], width=CONFIGURATION['image_size'])\n",
    "], additional_targets={\n",
    "    'albedo': 'image',\n",
    "    'depthmap': 'image'\n",
    "})\n",
    "\n",
    "triplet_concat_train_dataset = TripletDatasetConcatV2(data_dir=CONFIGURATION['data_dir'], transform=train_transform, train=True)\n",
    "triplet_concat_test_dataset = TripletDatasetConcatV2(data_dir=CONFIGURATION['data_dir'], transform=test_transform, train=False)\n",
    "\n",
    "\n",
    "triplet_concat_train_loader = DataLoader(\n",
    "    triplet_concat_train_dataset, \n",
    "    batch_size=CONFIGURATION['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "triplet_concat_test_loader = DataLoader(\n",
    "    triplet_concat_test_dataset, \n",
    "    batch_size=CONFIGURATION['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "roc_concat_train_dataset = CustomExrDatasetConCatV2(data_dir=CONFIGURATION['data_dir'], transform=train_transform, train=True)\n",
    "roc_concat_train_loader = DataLoader(\n",
    "    roc_concat_train_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    ")\n",
    "\n",
    "roc_concat_test_dataset = CustomExrDatasetConCatV2(data_dir=CONFIGURATION['data_dir'], transform=test_transform, train=False)\n",
    "roc_test_loader = DataLoader(\n",
    "    roc_concat_test_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    ")\n",
    "\n",
    "normal_checkpoint = torch.load(CONFIGURATION['normalmap_checkpoint'])\n",
    "new_normalmap_state_dict = {}\n",
    "for key, value in normal_checkpoint.items():\n",
    "    new_key = key[14:]  # Cắt bỏ 14 ký tự đầu tiên\n",
    "    new_normalmap_state_dict[new_key] = value\n",
    "    \n",
    "albedo_checkpoint = torch.load(CONFIGURATION['albedo_checkpoint'])\n",
    "new_albedo_state_dict = {}\n",
    "for key, value in albedo_checkpoint.items():\n",
    "    new_key = key[14:]  # Cắt bỏ 14 ký tự đầu tiên\n",
    "    new_albedo_state_dict[new_key] = value\n",
    "    \n",
    "depthmap_checkpoint = torch.load(CONFIGURATION['depthmap_checkpoint'])\n",
    "new_depthmap_state_dict = {}\n",
    "for key, value in depthmap_checkpoint.items():\n",
    "    new_key = key[14:]  # Cắt bỏ 14 ký tự đầu tiên\n",
    "    new_depthmap_state_dict[new_key] = value\n",
    "\n",
    "embedding_net = EmbeddingNet_Concat_V2(conf=CONFIGURATION)\n",
    "\n",
    "embedding_net.resnet1.load_state_dict(new_normalmap_state_dict)\n",
    "\n",
    "embedding_net.resnet2.load_state_dict(new_albedo_state_dict)\n",
    "\n",
    "embedding_net.resnet3.load_state_dict(new_depthmap_state_dict)\n",
    "\n",
    "model = TripletNet_Concat_V2(embedding_net).to(device)\n",
    "\n",
    "# Freeze 3 mạng lại\n",
    "for param in model.embedding_net.resnet1.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.embedding_net.resnet2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.embedding_net.resnet3.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "criterion = TripletLoss(CONFIGURATION['margin'])\n",
    "optimizer = Adam(model.parameters(), lr=CONFIGURATION['start_lr'])\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=30, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "earlystop_dir = os.path.abspath(CONFIGURATION['checkpoint_dir'] + CONFIGURATION['type'] + '/models')\n",
    "\n",
    "early_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['cosine_auc', 'euclidean_auc'],\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    verbose=0,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=0\n",
    ")      \n",
    "\n",
    "checkpoint_path = os.path.abspath(CONFIGURATION['checkpoint_dir'] + CONFIGURATION['type'] + '/models/checkpoint.pth')\n",
    "modle_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\ttrain: loss: 0.0421 | auc_cos: 0.9888 | auc_eu: 0.9944\n",
      "\ttest: loss: 0.4027 | auc_cos: 0.9496 | auc_eu: 0.9685\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n",
      "Epoch 2:\n",
      "\ttrain: loss: 0.1520 | auc_cos: 0.9823 | auc_eu: 0.9930\n",
      "\ttest: loss: 0.0841 | auc_cos: 0.9369 | auc_eu: 0.9642\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n",
      "Epoch 3:\n",
      "\ttrain: loss: 0.3882 | auc_cos: 0.9803 | auc_eu: 0.9892\n",
      "\ttest: loss: 0.0000 | auc_cos: 0.9459 | auc_eu: 0.9521\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n",
      "Epoch 4:\n",
      "\ttrain: loss: 0.6275 | auc_cos: 0.9821 | auc_eu: 0.9931\n",
      "\ttest: loss: 4.2305 | auc_cos: 0.9397 | auc_eu: 0.9627\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n",
      "Epoch 5:\n",
      "\ttrain: loss: 0.2789 | auc_cos: 0.9796 | auc_eu: 0.9890\n",
      "\ttest: loss: 4.6354 | auc_cos: 0.9446 | auc_eu: 0.9609\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n",
      "Epoch 6:\n",
      "\ttrain: loss: 0.4450 | auc_cos: 0.9819 | auc_eu: 0.9908\n",
      "\ttest: loss: 0.0653 | auc_cos: 0.9526 | auc_eu: 0.9703\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/checkpoint/test/concat/models/checkpoint.pth\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriplet_train_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriplet_concat_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriplet_test_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriplet_concat_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroc_train_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroc_concat_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroc_test_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroc_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_max_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodle_checkpoint\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/going_modular/train_eval/triplet/train.py:38\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(conf, start_epoch, model, triplet_train_loader, triplet_test_loader, criterion, optimizer, scheduler, epochs, device, roc_train_loader, roc_test_loader, early_max_stopping, model_checkpoint)\u001b[0m\n\u001b[1;32m     35\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Train stage\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriplet_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m test_epoch(triplet_test_loader, model, criterion, device)\n\u001b[1;32m     41\u001b[0m train_euclidean_auc, train_cosine_auc \u001b[38;5;241m=\u001b[39m compute_roc_auc(roc_train_loader, model, device)\n",
      "File \u001b[0;32m/media/vohoang/WorkSpace/ubuntu/projects/in-process/concat/going_modular/train_eval/triplet/train.py:86\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(triplet_train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     84\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, X \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(triplet_train_loader):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1402\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1404\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(\n",
    "    conf=CONFIGURATION,\n",
    "    start_epoch=0,\n",
    "    model=model,\n",
    "    triplet_train_loader=triplet_concat_train_loader, \n",
    "    triplet_test_loader=triplet_concat_test_loader, \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler, \n",
    "    epochs=CONFIGURATION['epochs'], \n",
    "    device=device,\n",
    "    roc_train_loader=roc_concat_train_loader, \n",
    "    roc_test_loader=roc_test_loader,\n",
    "    early_max_stopping=early_stopping,\n",
    "    model_checkpoint=modle_checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
